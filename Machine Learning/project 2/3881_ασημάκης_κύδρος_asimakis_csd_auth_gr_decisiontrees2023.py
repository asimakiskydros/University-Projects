# -*- coding: utf-8 -*-
"""3881_Ασημάκης_Κύδρος_asimakis@csd.auth.gr_DecisionTrees2023.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1biP4ESY6OdudmAHslqjzI8aGwY2Kc9Gd

## About iPython Notebooks ##

iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN SOLUTION #END CODE HERE` searching for the missing parts (usually denoted with `...`). After writing your code, you can run the cell by either pressing "SHIFT"+"ENTER" or by clicking on "Run" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\rightarrow$Run All).

 **What you need to remember:**

- Run your cells using SHIFT+ENTER (or "Run cell")
- Write code in the designated areas using Python 3 only
- Do not modify the code outside of the designated areas
- In some cases you will also need to explain the results. There will also be designated areas for that.

Fill in your **NAME** and **AEM** below:
"""

NAME = "Ασημάκης Κύδρος"
AEM = "3881"

"""---

# Assignment 2 - Decision Trees #

Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work.

After this assignment you will:
- Be able to use the scikit-learn library and train your own model from scratch.
- Be able to train and understand decision trees.
"""

# Always run this cell
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score, accuracy_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder

# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS
RANDOM_VARIABLE = 42

"""## 1. Scikit-Learn and Decision Trees ##

You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html).

**1.1** Load the breast cancer dataset using the scikit learn library. From variable *cdata*, you should export the *X* and *y*, from the *data* and *target* variables of the variable *cdata*, respectively, and the feature names and target names from the variables *feature_names* and *target_names*, respectively. Convert the latter two (feature names and target names) into lists. Thus, X and y should be numpy arrays, and feature_names and target_names should be lists. Then split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment.
"""

cdata = load_breast_cancer(as_frame=True)

# BEGIN SOLUTION
X = np.array(cdata['data'])
y = np.array(cdata['target'])
feature_names = list(cdata['feature_names'])
target_names = list(cdata['target_names'])
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_VARIABLE)

# END CODE HERE

print("Type of X: {}".format(type(X)))
print("Type of y: {}".format(type(y)))
print("Type of feature_names: {}".format(type(feature_names)))
print("Type of target_names: {}".format(type(target_names)))
print("Size of train set: {}".format(len(y_train)))
print("Size of test set: {}".format(len(y_test)))
print("Unique classes: {}".format(len(set(y_test))))

"""**Expected output**:  

```
Type of X: <class 'numpy.ndarray'>
Type of y: <class 'numpy.ndarray'>
Type of feature_names: <class 'list'>
Type of target_names: <class 'list'>
Size of train set: 381
Size of test set: 188
Unique classes: 2
```

**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other, set the *max_depth* to 3, and do not forget to use the *RANDOM_VARIABLE*, as it is crucial for the following part.
"""

# BEGIN SOLUTION
classifier_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=RANDOM_VARIABLE)
classifier_igain = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=RANDOM_VARIABLE)

# Train the model
classifier_gini.fit(X_train, y_train)
classifier_igain.fit(X_train, y_train)
# Perform predictions
prediction_gini = classifier_gini.predict(X_test)
prediction_igain = classifier_igain.predict(X_test)

# Evaluate using f1_score
f_measure_gini = f1_score(y_test, prediction_gini)
f_measure_igain = f1_score(y_test, prediction_igain)

# END CODE HERE

print("F-Measure Gini: {}".format(f_measure_gini))
print("F-Measure Information Gain: {}".format(f_measure_igain))

"""**Expected output**:

```
F-Measure Gini: 0.9663865546218487
F-Measure Information Gain: 0.979591836734694
```

**1.3** In this part, you are going to explore one of the trained decision trees visually. We will use the *classifier_igain* and the function *export_graphviz* to plot the decision tree. You should fill in the missing parts of the functions parameters, which correspond to the decision tree model, the feature names and the target names.
"""

# Let's see how our tree looks
from sklearn.tree import export_graphviz
from IPython.display import Image
from subprocess import call

# BEGIN SOLUTION
export_graphviz(
        decision_tree=classifier_igain,
        feature_names=feature_names,
        class_names=target_names,
        out_file="dtree.dot",
        rounded=True,
        filled=True
    )
# END CODE HERE

call(['dot', '-Tpng', 'dtree.dot', '-o', 'dtree.png', '-Gdpi=96'])
Image(filename = 'dtree.png')

"""**1.4** Now, we will examine two random instances (7th and 136th). Thus, we are presenting the decision tree's predictions for these instances, and the ground truth values. Moreover, for each instance, we print the feature values. However, as we can see from the plot above, only 6 features out of the 30 are being used by the tree. Thus, in order to print less information, we will use the *feature_importances_* variable of our tree to check which features has 0 importance to skip them."""

instance_a = 7
instance_b = 136
for instance in [instance_a, instance_b]:
  print(str(instance)+ 'th instance a was classified as: ' +target_names[prediction_igain[instance]] +' while the ground truth was: ' + target_names[y_test[instance]])
  # BEGIN SOLUTION
  for idf, feature_name in enumerate(feature_names):
    if  classifier_igain.feature_importances_[idf] != 0:
      print('\t'+feature_name+": "+str(X_test[instance][idf]))
  # END CODE HERE
  print('\n')

"""**Expected output**:

```
7th instance a was classified as: malignant while the ground truth was: malignant
	mean texture: 15.05
	mean concave points: 0.07953
	area error: 61.1
	worst radius: 20.01
	worst texture: 19.52
	worst perimeter: 134.9


136th instance a was classified as: malignant while the ground truth was: benign
	mean texture: 18.89
	mean concave points: 0.05381
	area error: 19.29
	worst radius: 14.8
	worst texture: 27.2
	worst perimeter: 97.33
```

**1.6** Based on the aforementioned information, and the plotted decision tree, identify one feature value that if changed in each instance, the predicted class will change as well. Specifically, you should find a feature value change that will be small. Answer in the following cell, either with code, or/and writing a small paragraph explaining the feature, the change and why the decision will change.
"""

# BEGIN SOLUTION
pass
# END CODE HERE

"""or/and

* The 7th instance passes through the two right-most branches of the tree before being assigned a classification, therefore the relevant metrics are 'mean concave points' and 'worst perimeter'. We can eyeball that, should 'mean concave points' change in value so the 7th instance goes to the left branch, it would ultimately still be classified as 'malignant'. On the other hand, if the 'worst perimeter' bound increased by 20.45, the 7th instance would be then classified as 'benign'.

* Using similar logic, we can see that the 'mean concave points', 'worst perimeter' and 'worst texture' features are what dictate the classification of the 136th instance. We can quickly eliminate 'worst perimeter' too, as if that (and that alone) changed, the instance would again be classified as 'malignant'. However,
changing the bounds of the other two features leads the instance to a different classification. We can thus estimate that the smallest change will be on 'mean concave points', by about 0.00281.

**1.7** Train multiple classifiers by modifying the max_depth within the range from 1 to 8 and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals.
"""

# BEGIN SOLUTION
fscores = {}
fscores['train'] = []
fscores['test'] = []
for i in range(1, 8):
    clf = DecisionTreeClassifier(max_depth=i, random_state=RANDOM_VARIABLE)
    clf.fit(X_train, y_train)
    fscores['train'].append(round(f1_score(y_train, clf.predict(X_train)) * 100, 2))
    fscores['test'].append(round(f1_score(y_test, clf.predict(X_test)) * 100, 2))
# END CODE HERE

print("Fscores Train: {}".format(fscores['train']))
print("Fscores Test:  {}".format(fscores['test']))

"""**Expected output**:  
```
Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]
Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]
```

**1.8** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?

As we can see, by increasing the maximum depth, the model scores progressively better on training. However, its scores on testing peak early and then start to ''wobble'' to lesser values.

Thus, we should choose by maximizing score gain on testing and, on a lesser note, minimizing score loss on training.

Judging by the above results, we should choose 3 as maximum depth.

## 2.0 Pipelines ##

In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  

**2.1** Load the train and test set variables from the files **income.csv** and **income_test.csv**
"""

# BEGIN SOLUTION
income_train = pd.read_csv('income.csv')
income_test = pd.read_csv('income_test.csv')

train_set = income_train.drop('income', axis=1)
y_train = income_train['income']

test_set = income_test.drop('income', axis=1)
y_test = income_test['income']
# End CODE HERE

"""**2.2** Check if there are any features with missing values in the data and report them. Check and report the numerical and categorical data, as well."""

# BEGIN SOLUTION
def report_null(__dataframe):
    flag = True
    temp = __dataframe.isna()
    for col in temp:
        if True in temp[col].values.tolist():
            flag = False
            print('   Feature \'{}\' has missing values'.format(col))
    print('   No features with missing values\n' if flag else '')

def seperate_dtypes(__dataframe):
    numeric = __dataframe.select_dtypes(include=[np.number])
    categorical = __dataframe.select_dtypes(exclude=[np.number])
    num = [column for column in numeric if column != 'income']
    cat = [column for column in categorical if column != 'income']
    return num, cat

print('Income train set:')
report_null(income_train)

print('Income test set:')
report_null(income_test)

num, cat = seperate_dtypes(income_train)
print('Columns with numerical data: {}'.format(num))
print('Columns with categorical data: {}'.format(cat))


# End CODE HERE

"""* Test set is clear of NaNs.
* Features 'workclass' and 'occupation' on train set have missing values.
* Features 'age', 'fnlwgt', 'education_num', 'capital-gain', 'capital-loss', 'hours-per-week' consist of numerical values, the rest are categorical

**2.3** Create your pipeline. An acceptable pipeline, should include both numerical and categorical handling.
"""

# BEGIN SOLUTION

# your pipeline!
clf = Pipeline(steps = [
        ('preprocessor', ColumnTransformer(transformers = [
                ('numerical', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean'))]), num),
                ('categorical', Pipeline(steps=[('encoder', OneHotEncoder(handle_unknown='ignore'))]), cat)
        ])),
        ('classifier', DecisionTreeClassifier())
] )

# train the pipeline
clf.fit(train_set, y_train)
# End CODE HERE

"""**2.4** Evaluate the pipeline's performance, without tuning!"""

# BEGIN SOLUTION
# perform the prediction to the test set
y_predict = clf.predict(test_set)
# End CODE HERE
print("Model score Accuracy: %.3f" % accuracy_score(y_test,y_predict))
print("Model score F1 Weighted: %.3f" % f1_score(y_test,y_predict,average='weighted'))

"""**2.5** Perform a gooood grid search to find the best parameters for your pipeline. Both GridSearchCV and RandomizedSearchCV are acceptable"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    "preprocessor__numerical__imputer__strategy": ["mean", "median"],
    "classifier__max_depth": [2, 5, 10],
    "classifier__criterion": ["gini","entropy"],
    "classifier__max_features": [0.25, 0.5, 0.75, None],
    "classifier__min_samples_leaf": [1,10,20,50]
}

grid_search = GridSearchCV(clf, param_grid, cv=5)
grid_search.fit(train_set, y_train)

print("Best params:")
print(grid_search.best_params_)

"""**2.6** Evaluate the best model's performance."""

# BEGIN SOLUTION
# perform the prediction to the test set

# this is the same as building a new model from the ground up using the above
# parameters, training it and then predicting through it.
y_predict = grid_search.predict(test_set)

# End CODE HERE
print("Model score Accuracy: %.3f" % accuracy_score(y_test,y_predict))
print("Model score F1 Weighted: %.3f" % f1_score(y_test,y_predict,average='weighted'))

"""**2.7** Evaluate your model using at least three different evaluation metrics (note1: except accuracy and weighted f1 score, note2: do not use more than once a variation of f1)."""

# BEGIN SOLUTION
from sklearn.metrics import balanced_accuracy_score, jaccard_score, recall_score

metric1 = balanced_accuracy_score(y_test, y_predict)
metric2 = jaccard_score(y_test, y_predict, pos_label='<=50K')
metric3 = recall_score(y_test, y_predict, pos_label='<=50K')
#END CODE HERE

print("Model score Metric 1: %.3f" % metric1)
print("Model score Metric 2: %.3f" % metric2)
print("Model score Metric 3: %.3f" % metric3)

"""**2.8** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following
- How do you handle missing values and why
- How do you handle categorical variables and why
- Any further preprocessing steps
- How do you evaluate your model and how did you choose its parameters
- Report any additional results and comments on your approach.

You should achieve at least 85% accuracy score and 84% f1 score.

* If numerical, the Imputer will autofill them with its built-in strategies. If categorical, the Encoder ignores them. This is done as errors are natural and, thus, wiping them before building the classifier would yield an unrealistic model. The model needs to be able to deal with them and recover from them unscathed.
* I pass them through a 'different' 'channel' so to speak, encoding them before feeding them to the Classifier. This is done so the classifier will be able to only deal with values, discrete or continuous.
* None
* I find the optimal parameters using the GridSearchCV. Then, instead of creating a model with these parameters manually, I simply predict through the aforementioned grid_search, which will use the best found parameters automatically. It scores around ~85% accuracy and F1 score.

**Bonus Question:** Did you like this assignment? Please provide your feedback.

* The 'expected output' problem was handled perfectly this time and should stay unchanged in future projects.
* The more abstract nature of this assignment complimented the choice of the IPYNB environment way better this time.
* I liked having more freedom in how i write my code.
* Short and to the point.
* I still wish the feedback section was anonymous.
* Overall a vast improvement from last time.
"""